{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os, json\n",
      "from collections import defaultdict\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from stop_words import get_stop_words\n",
      "from nltk.stem.porter import PorterStemmer\n",
      "from gensim import corpora, models\n",
      "import gensim\n",
      "import requests\n",
      "import Sentiment\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tokenizer = RegexpTokenizer(r'\\w+')\n",
      "en_stop = get_stop_words('en')\n",
      "p_stemmer = PorterStemmer()\n",
      "sentimentClassifier = Sentiment.SentimentLearner()\n",
      "pos_words,neg_words = sentimentClassifier.get_dictionaries()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getAppDetails(packageNames):\n",
      "    data = {}\n",
      "    try:\n",
      "        json_data=open('WDresponse.json').read()\n",
      "        data = json.loads(json_data)['apps']\n",
      "        print \"Got data from local file\"\n",
      "    except (ValueError, IOError) as err:\n",
      "        r = requests.post('http://api.wheredatapp.com/data', data=json.dumps({'packages':packageNames}),headers={'content-type': 'application/json'})\n",
      "        data = json.loads(r.text)['apps']\n",
      "        \n",
      "    app_dict = {}\n",
      "    for app in data:\n",
      "        app_dict[app['package']] = {'category':app['category'],\n",
      "                                    'name':app['title'],\n",
      "                                    'image':app['icon_url'],\n",
      "                                    'description': app['short_description'],\n",
      "                                    'usage_score':app['usage_score'],\n",
      "                                    'created': app['created']\n",
      "                                    }\n",
      "    \n",
      "    print len(app_dict.keys()), \" application details retrieved from api.wheredatapp.com\"\n",
      "    return app_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getAppData(reviewsThreshold = 100):\n",
      "    count = 0;\n",
      "    appReviews = defaultdict(lambda:defaultdict(list))\n",
      "    appReviewsCount = defaultdict(int)\n",
      "    for root, dirs, files in os.walk(\"../com\", topdown=False):\n",
      "        try:\n",
      "            if len(dirs) > 0 or 'reviews.json' not in files:\n",
      "                continue\n",
      "            \n",
      "            splitRoot = root.rsplit(\"/\",2)\n",
      "            version = splitRoot[2]\n",
      "            packageName = splitRoot[1]\n",
      "            # continue if dir is not empty or files does not contain reviews.json\n",
      "            for reviewFile in files:\n",
      "                \n",
      "                json_data=open(os.path.join(root, reviewFile)).read()\n",
      "                data = json.loads(json_data)\n",
      "                appReviewsCount[packageName] += len(data)\n",
      "                appReviews[packageName][version].extend(data)\n",
      "                count = count+1\n",
      "            '''\n",
      "            if count == 10:\n",
      "                break\n",
      "            '''\n",
      "        except (ValueError, IOError, IndexError) as err:\n",
      "            continue\n",
      "    \n",
      "    filtered_dict = {}#{k:v for (k,v) in appReviews.iteritems() if appReviewsCount[k] > 100}\n",
      "    \n",
      "    for k,v in appReviews.iteritems():\n",
      "        if appReviewsCount[k] > reviewsThreshold:\n",
      "            filtered_dict[k]=v\n",
      "\n",
      "    print count,\" files analysed, \",len(appReviews),\" applications analysed, \",len(filtered_dict),\" selected based on count\"\n",
      "    return filtered_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractReviews(data, stem = True):\n",
      "    docs = []\n",
      "    for reviews in data:\n",
      "        try:\n",
      "            comment = reviews['comment'] + '  '+ reviews['title']\n",
      "            timestamp = reviews['timestampMsec']\n",
      "            raw = comment.lower()\n",
      "            tokens = tokenizer.tokenize(raw)\n",
      "                            \n",
      "            # remove stop words from tokens\n",
      "            stopped_tokens = [i for i in tokens if not i in en_stop]\n",
      "                            \n",
      "            if stem:\n",
      "                stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
      "                docs.append(stemmed_tokens)\n",
      "            else:\n",
      "                docs.append(stopped_tokens)\n",
      "                            \n",
      "        except KeyError as er:\n",
      "            continue\n",
      "    return docs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractTopics(documents, num_topics = 3):\n",
      "    dictionary = corpora.Dictionary(documents)\n",
      "    non_topics = ['nice','awesome','love','please','good','like','using','doesn','perfect','better','sucks',\n",
      "                  'still','much','easy','great','fantastic','excellent','think','phone','every','really','though',\n",
      "                  'lovely','really','needs','seems','gives','horrible','really','always','looks','tried','piece'\n",
      "                  'takes','terrible','probably','keeps','work','quite','whenever','keeps','without','makes','stars',\n",
      "                  'sometimes','get','amazing','ask','happy','interesting','change','consider','useful','worst'\n",
      "                  'annoying','shows','given','especially']\n",
      "    \n",
      "    # convert tokenized documents into a document-term matrix\n",
      "    corpus = [dictionary.doc2bow(text) for text in documents]\n",
      "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics, id2word = dictionary, passes=20)\n",
      "    \n",
      "    word_list = set()\n",
      "    for topic in ldamodel.show_topics(num_topics=30,num_words = 20,formatted=False):\n",
      "        for word,score in topic[1]:\n",
      "            word_list.add(str(word))\n",
      "    \n",
      "    final_topics = set()\n",
      "    seen_roots = set()\n",
      "    for word in word_list:\n",
      "        if len(word) > 4 and word not in non_topics:\n",
      "            root = p_stemmer.stem(word)\n",
      "            if root not in non_topics and root not in seen_roots:\n",
      "                final_topics.add(word)\n",
      "                seen_roots.add(root)\n",
      "            \n",
      "    return final_topics,ldamodel.bound(corpus)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 115
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def generateCommentSentiments(reviews):\n",
      "    sMap = {}\n",
      "    bestScore = 0\n",
      "    worstScore = 0\n",
      "    bestReview = {}\n",
      "    worstReview = {}\n",
      "\n",
      "    for review in reviews:\n",
      "        if 'comment' not in review or 'commentId' not in review:\n",
      "            continue\n",
      "            \n",
      "        score = sentimentClassifier.classify_text(review['comment'])\n",
      "        sMap[review['commentId']] = score\n",
      "        if score > bestScore:\n",
      "            bestReview = review\n",
      "            bestScore = score\n",
      "            \n",
      "        elif score < worstScore:\n",
      "            worstReview = review\n",
      "            worstScore = score\n",
      "        \n",
      "    return sMap,bestReview, worstReview"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getSentimentScore(reviews, sentimentMap):\n",
      "    score = 0.0;\n",
      "    for review in reviews:\n",
      "        if review['commentId'] in sentimentMap:\n",
      "            score += sentimentMap[review['commentId']]\n",
      "    return score"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTopicSentiments(topics, sentimentMap, reviewList):\n",
      "    topicScores = defaultdict(float)\n",
      "    for review in reviewList:\n",
      "        for topic in topics:\n",
      "            if 'comment' in review and 'commentId' in review:\n",
      "                if topic in review['comment'] and review['commentId'] in sentimentMap:\n",
      "                    topicScores[topic] += sentimentMap[review['commentId']]\n",
      "    \n",
      "    return topicScores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getAverageRating(reviews):\n",
      "    if len(reviews) == 0:\n",
      "        return 0\n",
      "    ratingSum = 0.0\n",
      "    for review in reviews:\n",
      "        if 'starRating' in review:\n",
      "            ratingSum += review['starRating']\n",
      "    \n",
      "    return (ratingSum/len(reviews))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def extractAllAppData(reviewMap, appMetaInfo):\n",
      "    appMap = defaultdict(lambda : defaultdict(str))\n",
      "    count = 0\n",
      "    for packageName,versionReviews in reviewMap.iteritems():\n",
      "        currentPackage = appMetaInfo[packageName]\n",
      "        versions = defaultdict(lambda : defaultdict(str))\n",
      "        consolidatedReviews = []\n",
      "        \n",
      "        for version,reviews in versionReviews.iteritems():\n",
      "            versions[version]['numReviews'] = len(reviews)\n",
      "            versions[version]['avgRating'] = getAverageRating(reviews)\n",
      "            consolidatedReviews.extend(reviews)\n",
      "            \n",
      "        reviewCollection = extractReviews(consolidatedReviews, stem = False)\n",
      "        sentimentMap, bestReview, worstReview = generateCommentSentiments(consolidatedReviews)\n",
      "        \n",
      "        currentPackage['averageRating'] = getAverageRating(consolidatedReviews)\n",
      "        currentPackage['numReviews'] = len(consolidatedReviews)\n",
      "        currentPackage['sentimentScore'] = getSentimentScore(consolidatedReviews, sentimentMap)\n",
      "        currentPackage['bestReview'] = bestReview\n",
      "        currentPackage['worstReview'] = worstReview\n",
      "        #currentPackage['reviews'] = consolidatedReviews\n",
      "        \n",
      "        for version,reviews in versionReviews.iteritems():\n",
      "            versions[version]['sentimentScore'] = getSentimentScore(reviews, sentimentMap)\n",
      "            \n",
      "        currentPackage['versions'] = versions\n",
      "        \n",
      "        topics = extractTopics(reviewCollection, 3)\n",
      "        currentPackage['topics'] = getTopicSentiments(topics, sentimentMap, consolidatedReviews)\n",
      "        \n",
      "        appMap[packageName] = currentPackage\n",
      "        count = count + 1\n",
      "\n",
      "        if count  == 5:\n",
      "            print \"Done with \",count,\" applications\", \" time = \",time.time()\n",
      "            break\n",
      "    print \"Data for \",count,\" applications extracted\" \n",
      "    return appMap"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviewMap = getAppData()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "43399  files analysed,  28712  applications analysed,  500  selected based on count\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "appMetaInfo = getAppDetails(reviewMap.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Got data from local file\n",
        "500  application details retrieved from api.wheredatapp.com\n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "start = time.time()\n",
      "print \"Start time = \",start\n",
      "appInfo = extractAllAppData(reviewMap, appMetaInfo)\n",
      "end = time.time()\n",
      "print \"Final rum time = \",(end - start)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Start time =  1449084078.79\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 50  applications  time =  1449084404.32\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 100  applications  time =  1449084819.35\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 150  applications  time =  1449085194.77\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 200  applications  time =  1449085529.13\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 250  applications  time =  1449085813.9\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 300  applications  time =  1449086213.69\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 350  applications  time =  1449086619.32\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 400  applications  time =  1449087031.55\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 450  applications  time =  1449087427.28\n",
        "Done with "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 500  applications  time =  1449087851.96\n",
        "Data for  500  applications extracted\n",
        "Final rum time = "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 3773.22073913\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "f = open(\"apps.json\", \"w\")\n",
      "f.write(json.dumps({'apps':appInfo}))\n",
      "f.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getSentimentAccuracy(reviewMap):\n",
      "    threeMap = {True:0, False:0}\n",
      "    fourMap = {True:0, False:0}\n",
      "    fiveMap = {True:0, False:0}\n",
      "    starDis = defaultdict(int)\n",
      "    reviewCount = 0\n",
      "    for packageName,versionReviews in reviewMap.iteritems():\n",
      "        consolidatedReviews = []\n",
      "        \n",
      "        for version,reviews in versionReviews.iteritems():\n",
      "            consolidatedReviews.extend(reviews)\n",
      "        \n",
      "        for review in consolidatedReviews:\n",
      "            if 'starRating' in review:\n",
      "                starRating = review['starRating']\n",
      "                starDis[starRating] += 1\n",
      "                if 'comment' in review:\n",
      "                    reviewCount += 1\n",
      "                    score = sentimentClassifier.classify_text(review['comment'])\n",
      "                    if starRating >= 3:\n",
      "                        threeMap[score > 0] += 1\n",
      "                    if starRating >= 4:\n",
      "                        fourMap[score > 0] += 1\n",
      "                        \n",
      "                    if starRating >= 5:\n",
      "                        fiveMap[score > 0] += 1\n",
      "                    \n",
      "    print reviewCount, \" reviews analysed\"\n",
      "    print \"For 3 accuracy = \",float(threeMap[True])/sum(threeMap.values())\n",
      "    print \"For 4 accuracy = \",float(fourMap[True])/sum(fourMap.values())\n",
      "    print \"For 5 accuracy = \",float(fiveMap[True])/sum(fiveMap.values())\n",
      "    print \"Star dis = \"\n",
      "    for k,v in starDis.iteritems():\n",
      "        print k,v\n",
      "                \n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reviewMap2 = getAppData(reviewsThreshold=1)\n",
      "getSentimentAccuracy(reviewMap2)\n",
      "\n",
      "reviewMap2 = getAppData(reviewsThreshold=100)\n",
      "getSentimentAccuracy(reviewMap2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "43399  files analysed,  28712  applications analysed,  10084  selected based on count\n",
        "262731"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  reviews analysed\n",
        "For 3 accuracy =  0.680194666995\n",
        "For 4 accuracy =  0.710473744292\n",
        "43399"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  files analysed,  28712  applications analysed,  500  selected based on count\n",
        "98365"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  reviews analysed\n",
        "For 3 accuracy =  0.663793211619\n",
        "For 4 accuracy =  0.700172593322\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "getSentimentAccuracy(reviewMap2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "262731  reviews analysed\n",
        "For 3 accuracy =  0.680194666995\n",
        "For 4 accuracy =  0.710473744292\n",
        "For 5 accuracy =  0.736921024123\n",
        "Star dis = \n",
        "0 6\n",
        "1 38819\n",
        "2 12840\n",
        "3 22360\n",
        "4 38191\n",
        "5 153599\n"
       ]
      }
     ],
     "prompt_number": 119
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newMap = extractAllAppData(reviewMap, appMetaInfo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Done with  5  applications  time =  1449104188.09\n",
        "Data for  5  applications extracted\n"
       ]
      }
     ],
     "prompt_number": 69
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "newMap.keys()[1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 70,
       "text": [
        "'com.iloiacono.what2wear'"
       ]
      }
     ],
     "prompt_number": 70
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def computeTfIdf(reviews, term):\n",
      "    df = 0.0\n",
      "    tf = 0.0\n",
      "    totalDocs = 0.0\n",
      "    for review in reviews:\n",
      "        if 'comment' in review:\n",
      "            totalDocs += 1\n",
      "            tokens = tokenizer.tokenize(review['comment'].lower())\n",
      "            if term in tokens:\n",
      "                tf += float(tokens.count(term))/len(tokens)\n",
      "                df += 1\n",
      "    \n",
      "    df = float(df)/totalDocs\n",
      "    if df > 0:\n",
      "        return tf*df\n",
      "    return 0\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 113
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "for package,info in newMap.iteritems():\n",
      "    for topic in info['topics'].keys():\n",
      "        print \"Topic = \",topic,\" TFIDF = \",computeTfIdf(info['reviews'],topic)\n",
      "    print \"Topic = if, TFIDF = \",computeTfIdf(info['reviews'],'if')\n",
      "    print \"Topic = can, TFIDF = \",computeTfIdf(info['reviews'],'can')\n",
      "\n",
      "    print \"\\n\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Topic =  challenging  TFIDF =  0.0720717649105\n",
        "Topic =  stuck  TFIDF =  0.00470963346689\n",
        "Topic =  money  TFIDF =  0.0226131931093\n",
        "Topic =  object  TFIDF =  0.187738106924\n",
        "Topic =  bought  TFIDF =  0.0047367857485\n",
        "Topic =  puzzles  TFIDF =  0.103997093707\n",
        "Topic =  hints  TFIDF =  0.0229847698027\n",
        "Topic =  enough  TFIDF =  0.00402354758873\n",
        "Topic =  games  TFIDF =  0.139386157087\n",
        "Topic =  inventory  TFIDF =  0.000597759313289\n",
        "Topic =  mystic  TFIDF =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0217275030908\n",
        "Topic =  front  TFIDF =  0.000277142659184\n",
        "Topic =  diary  TFIDF =  0.0205911494182\n",
        "Topic =  hidden  TFIDF =  0.288253027661\n",
        "Topic =  waste  TFIDF =  0.0099234393404\n",
        "Topic =  expensive  TFIDF =  0.00217501873862\n",
        "Topic =  first  TFIDF =  0.0329687236721\n",
        "Topic = if, TFIDF =  0.0436903351173\n",
        "Topic = can, TFIDF =  0.0891930851037\n",
        "\n",
        "\n",
        "\n",
        "Topic =  given  TFIDF =  0.0222222222222\n",
        "Topic =  loading  TFIDF =  0.00661157024793\n",
        "Topic =  temperature  TFIDF =  0.0303267045455\n",
        "Topic =  suddenly  TFIDF =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0222222222222\n",
        "Topic =  decent  TFIDF =  0.00330578512397\n",
        "Topic =  signal  TFIDF =  0.00661157024793\n",
        "Topic =  setting  TFIDF =  0.00661157024793\n",
        "Topic =  fixed  TFIDF =  0.0795454545455\n",
        "Topic =  weather  TFIDF =  0.337484750098\n",
        "Topic =  location  TFIDF =  0.0349173553719\n",
        "Topic =  suggestion  TFIDF =  0.00661157024793\n",
        "Topic =  turns  TFIDF =  0.02\n",
        "Topic =  accurate  TFIDF =  0.07578125\n",
        "Topic =  instantly  TFIDF =  0.02\n",
        "Topic =  especially  TFIDF =  0.101587301587\n",
        "Topic =  annoying  TFIDF =  0.02\n",
        "Topic =  changes  TFIDF =  0.101587301587\n",
        "Topic =  reliable  TFIDF =  0.0955004591368\n",
        "Topic =  shows  TFIDF =  0.0222222222222\n",
        "Topic =  clothes  TFIDF =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.00661157024793\n",
        "Topic = if, TFIDF =  0\n",
        "Topic = can, TFIDF =  0.0354219643992\n",
        "\n",
        "\n",
        "\n",
        "Topic =  available  TFIDF =  0.0173076923077\n",
        "Topic =  takes  TFIDF =  0.07668997669\n",
        "Topic =  german  TFIDF =  0.0034188034188\n",
        "Topic =  movie  TFIDF =  0.00719526627219\n",
        "Topic =  error  TFIDF =  0.0017094017094\n",
        "Topic =  freezing  TFIDF =  0.00384615384615\n",
        "Topic =  streams  TFIDF =  0.00236686390533\n",
        "Topic =  english  TFIDF =  0.135970695971\n",
        "Topic =  download  TFIDF =  0.00384615384615\n",
        "Topic =  android  TFIDF =  0.0094674556213\n",
        "Topic =  movie4k  TFIDF =  0.0319230769231\n",
        "Topic =  trouble  TFIDF =  0.00384615384615\n",
        "Topic =  uninstall  TFIDF =  0.00615384615385\n",
        "Topic = if, TFIDF =  0.00236686390533\n",
        "Topic = can, TFIDF =  0.00692307692308\n",
        "\n",
        "\n",
        "\n",
        "Topic =  sound  TFIDF =  0.00767973856209\n",
        "Topic =  updated  TFIDF =  0.0106378169997\n",
        "Topic =  features  TFIDF =  0.00606060606061\n",
        "Topic =  chinese  TFIDF =  0.0513482759374\n",
        "Topic =  modern  TFIDF =  0.000121951219512\n",
        "Topic =  style  TFIDF =  0.00424653034409\n",
        "Topic =  version  TFIDF =  0.0491607781927\n",
        "Topic =  tencent  TFIDF =  0.0112590900596\n",
        "Topic =  verification  TFIDF =  0.00671855921856\n",
        "Topic =  english  TFIDF =  0.0595027623562\n",
        "Topic =  design  TFIDF =  0.0227083333333\n",
        "Topic =  message  TFIDF =  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0338808745602\n",
        "Topic =  voice  TFIDF =  0.00239898989899\n",
        "Topic =  android  TFIDF =  0.0746197089947\n",
        "Topic =  friend  TFIDF =  0.0305195038056\n",
        "Topic =  permissions  TFIDF =  0.0045\n",
        "Topic = if, TFIDF =  0.0379032615959\n",
        "Topic = can, TFIDF =  0.150292457774\n",
        "\n",
        "\n",
        "\n",
        "Topic =  football  TFIDF =  0.0627776325029\n",
        "Topic =  update  TFIDF =  0.0467478371974\n",
        "Topic =  player  TFIDF =  0.0541073238659\n",
        "Topic =  manager  TFIDF =  0.0690017404872\n",
        "Topic =  maintenance  TFIDF =  0.00910925186832\n",
        "Topic =  fixed  TFIDF =  0.0121125655703\n",
        "Topic =  match  TFIDF =  0.00491184671636\n",
        "Topic = if, TFIDF =  0.0414948955929\n",
        "Topic = can, TFIDF =  0.0538020696098\n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Estimate the variational bound of documents from corpus: E_q[log p(corpus)] - E_q[log q(corpus)]\n",
      "bounds = []\n",
      "for package,info in newMap.iteritems():\n",
      "    reviewCollection = extractReviews(info['reviews'], stem = False)\n",
      "    topics, bound = extractTopics(reviewCollection, 3)\n",
      "    bounds.append(bound)\n",
      "    print package,\" - \",bound\n",
      "    \n",
      "print sum(bounds)/len(bounds)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "com.sunraygames.md2hifree  -  -16419.783326\n",
        "com.iloiacono.what2wear"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  -  -11640.4865516\n",
        "com.wKinoMovies"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  -  -3085.74370892\n",
        "com.tencent.mobileqqi"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  -  -11695.4937471\n",
        "com.actoz.OneForEleven"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  -  -14855.6892617\n",
        "-11539.4393191\n"
       ]
      }
     ],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}